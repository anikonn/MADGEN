#exp: "nist23_full_inst_rand"  #"among_nce_full_inst_rand" #"among_nce_all_inst" #"among_nce_all_prec_inst" #"canopus" #"nist23" #"CASMI" # "MoNA" # "massspecgym"
exp: "canopus"
fp_path: "ecfp_3_4096"
use_sampling: False
element_list: ['Se', 'Si', 'S', 'N', 'I', 'B', 'Br', 'Cl', 'F', 'C', 'O', 'P'] # canopus
atom_feature: 'full'
bond_feature: 'full'
batch_size_train_contr: 32
batch_size_train_contr_cand: 32
batch_size_train_final: 64
batch_size_val_final: 128
spec_type: ['[M+H]+']
# spec_type: ['[M+H]+', '[M+Na]+']
load_dicts: True
ignore_test_contr: True
num_epoch_contr: 1000
num_epoch_final: 100
contr_temp: 0.05
aug_cands: False
aug_cands_wt: 0.1
cand_aug_random: False
gnn_channels: [64,128,256, 512, 1024]
attn_heads: [12,12,12, 12,12]
gnn_type: "gcn"
num_gnn_layers: 5
gnn_hidden_dim: 1024
gnn_out_feat: 196
global_pooling: "max"
gnn_dropout: 0.2
contr_lr: 0.0005
# final_lr: 1.0e-4 #for canopus
final_lr: 0.5e-5
final_embedding_dim: 1024
fc_dropout: 0.4
spec_embedding_dim: 1024
debug: True
logfile: 'run.log'
mz_log_low: -2
mz_log_high: 3
mz_spacing: 'log'
mz_precision: 32
resolution: 1
max_mz: 1000
mz_transformation: 'log10over3'
sinus_embed_dim: 64
aggregator: 'sum' #max, sum, mean, maxpool
wt_contr: 0.5
wt_fp: 0.5
fp_len: 4096
frz_contr: True
contr_trg: True
augment: False
fp_loss: 'bce' # bce, cos
data_dir: 'data/'
early_stopping_patience: 50
early_stopping_patience_contr: 100
tfm_dim: 512
tfm_dropout: 0.1
tfm_nhead: 4
num_tfm_layers: 3
dim_feedforward: 256
spec_enc: 'MLP_BIN' #'MLP_BIN', 'MLP_SIN', 'TFM'
inter: False #whether predicting interaction
# warmup_fraction: 0.01
# n_layers: 5
# hidden_mlp_dims: {'X': 256, 'E': 128, 'y': 128, 's': 256}
# hidden_dims: {'dx': 64, 'de': 64, 'dy': 64, 'ds': 64, 'dh': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}
# pretrained_mol_enc_model: 
# pretrained_spec_enc_model: 

# #1722269183992 MSGym
#1727094896692 Canopus
#1726780253748 NIST23
